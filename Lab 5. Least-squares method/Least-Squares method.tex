\documentclass[letterpaper]{article}
\usepackage{textcomp}
\usepackage{amsmath}
%\usepackage{IEEEtrantools}
%\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{verbatim}
\usepackage{graphicx}

\pagestyle{headings}
\title{PHYS 2030 \\Lab 5}
\usepackage[pdftex]{hyperref}
\begin{document}

\maketitle
Finish as many parts of the problem set as possible (and do not worry if you cannot finish all of them, since there is a lot to do).

Suggestions: 
\begin{itemize}
\item Put lots of comments in your code. You might use some parts of the code for your next assignments (or projects), and one thing you do not want to do is to spend time on trying to recall after couple of months what does your code do and why does it do it in that particular way. In addition, commenting will help you track down any logical errors, which are very hard to find in general.
\item  Use meaningful names for your variables (even if they turn out to get somewhat long). The reason for this is the same as above.
\item Do not just comment the particular lines of your code, but you can break your code into logical sections and give clear explanation of what is this section for.
\end{itemize}

\emph{You do not have to hand in anything and this problem set is not going to be graded.} 
\begin{enumerate}
\item Least-squares method is based on minimizing some quantity, that one chooses to reasonably well quantify the quality of the fit. 

If a set of data, $\{x_i,y_i\}$ is given, such that $\{\sigma_{i}\}$ is the corresponding set of uncertainties, obtained from normally distributed data, then we define the quality of the fit in the following way
\begin{equation*}
\chi^2=\sum{\dfrac{(f(x_i)-y_i)^2}{{\sigma_i}^2}},
\end{equation*}
where $f(x)$ is the fit function.
In general $\chi^2$ is a function of fit parameters, $\{C_i\}$, \dots etc that we want to find and the problem of finding these parameters can be written as,
\begin{equation*}
\chi^2(\{C_i\})=\sum{\dfrac{(f(x_i, \{C_i\})-y_i)^2}{{\sigma_i}^2}}
\end{equation*}
This needs to be minimized with respect to each parameter:
\begin{equation*}
\dfrac{d \chi^2(\{C_i\})}{d C_j}=0, j=1,\cdots, M
\end{equation*}
In general this gives a set of non-linear equations of the following form
\begin{equation*}
\sum{\dfrac{(f(x_i, \{C_i\})-y_i)}{{\sigma_i}^2}} \dfrac{\partial f(x_i,\{C_i\})}{\partial C_j}=0 , j=1,\cdots,M
\end{equation*}
In principle one can bring these equation into matrix form and solve it for unknown parameters with Matlab backslash command.
\begin{itemize}
\item Construct the matrix equation described above for 
\begin{equation*}
f(x,C_1,C_2)=C_1 x+C_2
\end{equation*}
\item Generate noisy set of data with linear relationship. Your $\{y_i\}$ data should have randomly generated set of uncertainties.
\item Find the parameters that will minimize Chi-Squared for your data. For this you can simply use Matlab backslash command, which will spit out the parameters for you. \footnote{You have already done this in your previous assignment, but now you will not use explicit formula for the parameters, but let MatLab to handle this simple, but tedious task.}
\item Now use Matlab built-in function \verb|polyfit| (read \textbf{Help} file for it) and find the fit parameters with it.
\item Plot the data and the fit, and calculated Chi-Squared. How good is your fit?
\item Now construct matrix equation described above for
\begin{equation*}
f(x,C_1,C_2,C_3)=C_1 x^2+C_2 x+C_3,
\end{equation*}
which is second-order polynomial. This should not be hard, especially if you understood how to find the parameters for the linear case (which is first-order polynomial).
\item As before, construct noisy second-order polynomial data with random uncertainties for $\{y_i\}$ data.
\item Find the fit parameters
\item Plot your data, fit function and fit constructed from \verb|polyfit|. Calculate Chi-Squared.
\end{itemize}
\item Sometimes fit function $f(x,\{C_i\})$ is nonlinear. In this case it is much harder (or impossible) to find the parameters that will minimize Chi-Squared. Below we will look at the nonlinear function whose parameters can be found in several ways.
\begin{itemize}
\item Consider $f(x_,A,\lambda)=A e^{\lambda x}$. We can take natural log of both sides and obtain 
\begin{equation}
\label{eq:ExpLin}
\ln(f(x_,A,\lambda))=\ln(A)+\lambda x
\end{equation}
\item Generate noisy data with exponential behavior. Find fit parameters for equation \ref{eq:ExpLin}. From these parameters obtain $\{A,\lambda\}$. (Note that the generated data has to be converted into 'log scale' as well.)
\item Now use 'brute-force' grid search method (as was described during the lectures) to find the parameters.
\item Use \verb|fminsearch| to find the parameters.
\item Plot your data and fit functions obtained by methods outlined above. 
\end{itemize}
\end{enumerate}

\end{document}